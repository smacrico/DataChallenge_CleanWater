{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Improved Benchmark Model\n",
    "\n",
    "This notebook:\n",
    "- Loads and merges water quality, Landsat, and TerraClimate datasets\n",
    "- Trains XGBoost models using optimized hyperparameters\n",
    "- Evaluates performance with RÂ² and RMSE metrics\n",
    "- Saves trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_loading import (\n",
    "    load_water_quality_data,\n",
    "    load_landsat_data,\n",
    "    load_terraclimate_data,\n",
    "    merge_all_datasets,\n",
    "    handle_missing_values,\n",
    "    split_features_target\n",
    ")\n",
    "from model_training import (\n",
    "    train_xgboost_model,\n",
    "    evaluate_model,\n",
    "    save_model,\n",
    "    BEST_XGB_PARAMS,\n",
    "    get_feature_importance\n",
    ")\n",
    "from utils import setup_logging, calculate_metrics, print_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load water quality data\n",
    "train_wq, test_wq, submission_template = load_water_quality_data(\n",
    "    train_path='../data/raw/train.csv',\n",
    "    test_path='../data/raw/test.csv',\n",
    "    submission_template_path='../data/raw/submission_template.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Landsat data\n",
    "train_landsat, test_landsat = load_landsat_data(\n",
    "    train_landsat_path='../data/raw/train_landsat.csv',\n",
    "    test_landsat_path='../data/raw/test_landsat.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TerraClimate data\n",
    "train_climate, test_climate = load_terraclimate_data(\n",
    "    train_climate_path='../data/raw/train_terraclimate.csv',\n",
    "    test_climate_path='../data/raw/test_terraclimate.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Merge Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training datasets\n",
    "train_merged = merge_all_datasets(train_wq, train_landsat, train_climate)\n",
    "print(f\"\\nTraining data shape: {train_merged.shape}\")\n",
    "print(f\"Columns: {list(train_merged.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge test datasets\n",
    "test_merged = merge_all_datasets(test_wq, test_landsat, test_climate)\n",
    "print(f\"\\nTest data shape: {test_merged.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with median\n",
    "train_merged = handle_missing_values(train_merged, strategy='median')\n",
    "test_merged = handle_missing_values(test_merged, strategy='median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns to drop\n",
    "drop_cols = ['uid', 'date'] if 'uid' in train_merged.columns else []\n",
    "if 'date' in train_merged.columns:\n",
    "    drop_cols.append('date')\n",
    "\n",
    "# Split features and target\n",
    "X_train_full, y_train_full = split_features_target(\n",
    "    train_merged,\n",
    "    target_col='target',\n",
    "    drop_cols=drop_cols\n",
    ")\n",
    "\n",
    "X_test, _ = split_features_target(\n",
    "    test_merged,\n",
    "    target_col='target',\n",
    "    drop_cols=drop_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {X_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display parameters\n",
    "print(\"Training with BEST_XGB_PARAMS:\")\n",
    "for key, value in BEST_XGB_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "model = train_xgboost_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    params=BEST_XGB_PARAMS,\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on training set\n",
    "train_metrics = evaluate_model(model, X_train, y_train, \"Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "val_metrics = evaluate_model(model, X_val, y_val, \"Validation Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "importance_df = get_feature_importance(\n",
    "    model,\n",
    "    X_train.columns.tolist(),\n",
    "    top_n=20\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 Most Important Features:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/figures/feature_importance_benchmark.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "save_model(model, '../models/xgboost_benchmark.pkl')\n",
    "print(\"\\nBenchmark model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This notebook established a strong benchmark model using:\n",
    "- Merged water quality, Landsat, and TerraClimate data\n",
    "- Optimized XGBoost hyperparameters\n",
    "- Proper train/validation split\n",
    "\n",
    "Next steps:\n",
    "- Engineer additional features (Notebook 02)\n",
    "- Add geospatial features (Notebook 03)\n",
    "- Implement full training pipeline (Notebook 04)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
